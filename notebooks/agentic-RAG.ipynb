{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d:\\DANG NHI\\repos\\master-llm-rag-vnlaw\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "while os.getcwd().split('\\\\')[-1] != 'master-llm-rag-vnlaw':\n",
    "    os.chdir('..')\n",
    "    print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ollama\n",
    "import asyncio\n",
    "from ollama import AsyncClient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vector database và Embedding model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromadb\n",
    "from chromadb import Settings, EmbeddingFunction, Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['VNLaws']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client = chromadb.PersistentClient(\n",
    "    path=\"./chroma_db\",\n",
    "    settings=Settings(allow_reset=True,),)\n",
    "\n",
    "client.list_collections()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20921"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collection = client.get_collection(name=\"VNLaws\")\n",
    "collection.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model ready !!!\n"
     ]
    }
   ],
   "source": [
    "base_model_id = \"FacebookAI/xlm-roberta-base\"\n",
    "trained_model_path = \"./models/trained_embedding_small_data/\"\n",
    "data_path = \"data/\"\n",
    "\n",
    "MAX_LEN = 512\n",
    "OVERLAP = 50\n",
    "\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(base_model_id)\n",
    "model = AutoModel.from_pretrained(trained_model_path)\n",
    "model.eval()\n",
    "\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device = torch.device('cpu')\n",
    "model.to(device)\n",
    "\n",
    "print(\"Model ready !!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyEmbeddingFunction(EmbeddingFunction):\n",
    "    def __init__(self, model, tokenizer, max_length=512):\n",
    "        self.model = model\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "\n",
    "    def embed_documents(self, texts):\n",
    "        inputs = self.tokenizer(texts, \n",
    "                                padding='max_length', \n",
    "                                max_length=self.max_length, \n",
    "                                return_tensors=\"pt\")\n",
    "        with torch.no_grad():\n",
    "            inputs = {key: value.to(device) for key, value in inputs.items()}\n",
    "            embeddings = self.model(**inputs).pooler_output\n",
    "    \n",
    "        return embeddings.cpu().numpy()\n",
    "\n",
    "    def embed_query(self, text):\n",
    "        inputs = self.tokenizer(text, return_tensors=\"pt\")\n",
    "        with torch.no_grad():\n",
    "            inputs = {key: value.to(device) for key, value in inputs.items()}\n",
    "            embeddings = self.model(**inputs).pooler_output\n",
    "        return embeddings.cpu().numpy()\n",
    "\n",
    "myembed = MyEmbeddingFunction(model, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine similarity:\n",
      " [[0.82892543]]\n"
     ]
    }
   ],
   "source": [
    "# text = 'Tôi đi học'\n",
    "# with torch.no_grad():\n",
    "#     token = tokenizer(text, return_tensors='pt', padding='max_length', truncation=True, max_length=MAX_LEN)\n",
    "#     output = model(**token)\n",
    "\n",
    "output = myembed.embed_documents([\"Tôi đi học\"])\n",
    "output1 = myembed.embed_query(\"Tôi đang viết trên bảng ở trường\")\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "similarity = cosine_similarity(output.reshape(1, -1), output1.reshape(1, -1))\n",
    "print(f\"Cosine similarity:\\n {similarity}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create ollama client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "ollama_api_url = \"https://1ef6-34-168-188-244.ngrok-free.app/\" # Thay đổi mỗi lần host"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "ollama_client = ollama.Client(\n",
    "    host=ollama_api_url,\n",
    "    headers = {'Header': 'application/json'}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"Xây dựng chương trình RAG với chatbot trung thực.\\n\" \\\n",
    "\"Tôi có bộ dữ liệu gồm các Lĩnh vực pháp luật Việt Nam bao gồm Bảo Hiểm, Lao Động, Nhà Đất và Tài Chính Ngân Hàng. \" \\\n",
    "\"Trong đó bao bồm các văn bản hành chính của Chính phủ.\\n\"\n",
    "\n",
    "agent_judgment1 = 'Bạn là một agent dùng để đánh giá câu trả lời. ' \\\n",
    "'Với câu hỏi \"{question}\", Bạn có thể trả lời câu hỏi bằng cơ sở dữ liệu của tôi được hay không (trả lời 1 nếu có thể, trả lời 0 nếu không thế).' \\\n",
    "'Trả lời:' \\\n",
    "\n",
    "agent_search_plan = 'Bạn là một agent để dự đoán thông tin cần truy vấn.\\n' \\\n",
    "'Theo bạn để trả lời câu hỏi \"{question}\", thì cần những thông tin gì và đến từ Lĩnh vực nào?\\n' \\\n",
    "'Trả lời tối đa 3 dòng và theo cú pháp \"<linh_vuc>: <thong_tin_can>\", linh_vuc chỉ duy nhất một, 3 câu trả lời cho thể trùng Lĩnh vực nhưng khác nhau thông tin cần.\\n' \\\n",
    "'Trả lời: '\n",
    "\n",
    "agent_judgment2 = 'Bạn là một agent reranking' \\\n",
    "\n",
    "# question = \"Quần đảo Trường Sa thuộc tỉnh nào?\"\n",
    "question = \"Tôi có thể làm gì với hợp đồng lao động?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# judment1: Trả lời được hay không\n",
    "response = ollama_client.chat(\n",
    "    model=\"gemma3:12b\",\n",
    "    messages=[{\"role\": \"user\", \"content\": system_prompt + agent_judgment1.format(question=question)}],\n",
    "    stream=False,\n",
    ")\n",
    "\n",
    "print(response.message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lao Động: Các quyền và nghĩa vụ của người lao động và người sử dụng lao động theo hợp đồng lao động.\n",
      "Nhà Đất: Các quy định pháp luật về quyền sở hữu và sử dụng tài sản liên quan đến hợp đồng lao động (nếu có).\n",
      "Tài Chính Ngân Hàng: Các vấn đề về thanh toán, khấu trừ, và các nghĩa vụ tài chính khác phát sinh từ hợp đồng lao động.\n",
      "\n",
      "Có thể trả lời được\n"
     ]
    }
   ],
   "source": [
    "def parse_judgment(response_text: str) -> int:\n",
    "    for char in response_text.strip():\n",
    "        if char in ['0', '1']:\n",
    "            return int(char)\n",
    "    return 0\n",
    "\n",
    "if parse_judgment(response.message.content) == 1:\n",
    "    print(\"Có thể trả lời được\")\n",
    "\n",
    "    response = ollama_client.chat(\n",
    "        model=\"gemma3:12b\",\n",
    "        messages=[{\"role\": \"user\", \"content\": system_prompt + agent_search_plan.format(question=question)}],\n",
    "        stream=False,\n",
    "    )\n",
    "    plans = response.message.content.split('\\n')\n",
    "    \n",
    "\n",
    "else:\n",
    "    print(\"Không thể trả lời được\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PROMPT = agent_search_plan.format(question=question)\n",
    "\n",
    "\n",
    "\n",
    "PROMPT = system_prompt + agent_search_plan.format(question=question)\n",
    "print(PROMPT)\n",
    "\n",
    "response = ollama_client.chat(\n",
    "    model='gemma3:12b', \n",
    "    messages=[{'role': 'user','content': PROMPT,}],\n",
    "    stream=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Nhà Đất>: Thông tin về phạm vi hành chính và địa lý Việt Nam để xác định tỉnh quản lý quần đảo Trường Sa.\n",
      "<Tài Chính Ngân Hàng>: Các văn bản pháp luật liên quan đến quản lý và khai thác tài nguyên biển đảo, có thể đề cập đến việc xác định chủ quyền.\n",
      "<Bảo Hiểm>: Các quy định về bảo hiểm cho hoạt động thăm dò, khai thác và bảo vệ chủ quyền trên quần đảo Trường Sa (gián tiếp liên quan đến xác định thuộc tỉnh nào).\n"
     ]
    }
   ],
   "source": [
    "print(response.message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tôi có một sơ bộ dữ liệu gồm các lĩnh vực pháp luật Việt Nam bao gồm Bảo Hiểm, Dân sự, Doanh Nghiệp và Giáo dục. Trong đó bao bồm các văn bản hành chính của Chính phủ.\n",
      "Theo bạn để trả lời câu hỏi \"Bảng giá dịch vụ khám chữa bệnh có bảo hiểm\", thì cần những thông tin gì và đến từ Lĩnh vực nào?\n",
      "Trả lời tối đa 3 dòng và theo mẫu <linh_vuc>: <thong_tin_can>, linh_vuc chỉ duy nhất một, 3 câu trả lời cho thể trung Lĩnh vực nhưng khác nhau thông tin cần.\n",
      "Trả lời: \n"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm-mining",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
