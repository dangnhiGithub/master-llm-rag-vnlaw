{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\Desktop\\DANG NHI\\repos\\master-llm-rag-vnlaw\n"
     ]
    }
   ],
   "source": [
    "# Điều hướng ra folder chủ\n",
    "import os\n",
    "while os.getcwd().split('\\\\')[-1] != 'master-llm-rag-vnlaw':\n",
    "    os.chdir('..')\n",
    "    print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ollama\n",
    "import asyncio\n",
    "from ollama import AsyncClient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create ollama client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ollama_api_url = \"https://9e7d-34-23-184-122.ngrok-free.app\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ollama_client = ollama.Client(\n",
    "    host=ollama_api_url,\n",
    "    headers = {'Header': 'application/json'}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tôi có một sơ bộ dữ liệu gồm các lĩnh vực pháp luật Việt Nam bao gồm Bảo Hiểm, Dân sự, Doanh Nghiệp và Giáo dục. Trong đó bao bồm các văn bản hành chính của Chính phủ.\n",
      "Bạn là một agent để dự đoán thông tin cần truy vấn.\n",
      "Theo bạn để trả lời câu hỏi \"Bảng giá dịch vụ khám chữa bệnh có bảo hiểm\", thì cần những thông tin gì và đến từ Lĩnh vực nào?\n",
      "Trả lời tối đa 3 dòng và theo mẫu <linh_vuc>: <thong_tin_can>, linh_vuc chỉ duy nhất một, 3 câu trả lời cho thể trung Lĩnh vực nhưng khác nhau thông tin cần.\n",
      "Trả lời: \n"
     ]
    },
    {
     "ename": "ResponseError",
     "evalue": "ngrok gateway error\nThe server returned an invalid or incomplete HTTP response.\r\n\r\nERR_NGROK_3004\r\n (status code: 503)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mResponseError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[47], line 24\u001b[0m\n\u001b[0;32m     21\u001b[0m PROMPT \u001b[38;5;241m=\u001b[39m system_prompt \u001b[38;5;241m+\u001b[39m agent_search_plan\u001b[38;5;241m.\u001b[39mformat(question\u001b[38;5;241m=\u001b[39mquestion)\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28mprint\u001b[39m(PROMPT)\n\u001b[1;32m---> 24\u001b[0m response \u001b[38;5;241m=\u001b[39m ollama_client\u001b[38;5;241m.\u001b[39mchat(model\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgemma3:12b\u001b[39m\u001b[38;5;124m'\u001b[39m, messages\u001b[38;5;241m=\u001b[39m[\n\u001b[0;32m     25\u001b[0m   {\n\u001b[0;32m     26\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     27\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m'\u001b[39m: PROMPT,\n\u001b[0;32m     28\u001b[0m     \u001b[38;5;66;03m# 'stream': True\u001b[39;00m\n\u001b[0;32m     29\u001b[0m   },\n\u001b[0;32m     30\u001b[0m ], stream\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\Admin\\miniconda3\\envs\\master\\Lib\\site-packages\\ollama\\_client.py:333\u001b[0m, in \u001b[0;36mClient.chat\u001b[1;34m(self, model, messages, tools, stream, format, options, keep_alive)\u001b[0m\n\u001b[0;32m    289\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mchat\u001b[39m(\n\u001b[0;32m    290\u001b[0m   \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    291\u001b[0m   model: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    298\u001b[0m   keep_alive: Optional[Union[\u001b[38;5;28mfloat\u001b[39m, \u001b[38;5;28mstr\u001b[39m]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    299\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Union[ChatResponse, Iterator[ChatResponse]]:\n\u001b[0;32m    300\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    301\u001b[0m \u001b[38;5;124;03m  Create a chat response using the requested model.\u001b[39;00m\n\u001b[0;32m    302\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    331\u001b[0m \u001b[38;5;124;03m  Returns `ChatResponse` if `stream` is `False`, otherwise returns a `ChatResponse` generator.\u001b[39;00m\n\u001b[0;32m    332\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[1;32m--> 333\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_request(\n\u001b[0;32m    334\u001b[0m     ChatResponse,\n\u001b[0;32m    335\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPOST\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m    336\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/api/chat\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m    337\u001b[0m     json\u001b[38;5;241m=\u001b[39mChatRequest(\n\u001b[0;32m    338\u001b[0m       model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[0;32m    339\u001b[0m       messages\u001b[38;5;241m=\u001b[39m[message \u001b[38;5;28;01mfor\u001b[39;00m message \u001b[38;5;129;01min\u001b[39;00m _copy_messages(messages)],\n\u001b[0;32m    340\u001b[0m       tools\u001b[38;5;241m=\u001b[39m[tool \u001b[38;5;28;01mfor\u001b[39;00m tool \u001b[38;5;129;01min\u001b[39;00m _copy_tools(tools)],\n\u001b[0;32m    341\u001b[0m       stream\u001b[38;5;241m=\u001b[39mstream,\n\u001b[0;32m    342\u001b[0m       \u001b[38;5;28mformat\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mformat\u001b[39m,\n\u001b[0;32m    343\u001b[0m       options\u001b[38;5;241m=\u001b[39moptions,\n\u001b[0;32m    344\u001b[0m       keep_alive\u001b[38;5;241m=\u001b[39mkeep_alive,\n\u001b[0;32m    345\u001b[0m     )\u001b[38;5;241m.\u001b[39mmodel_dump(exclude_none\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m),\n\u001b[0;32m    346\u001b[0m     stream\u001b[38;5;241m=\u001b[39mstream,\n\u001b[0;32m    347\u001b[0m   )\n",
      "File \u001b[1;32mc:\\Users\\Admin\\miniconda3\\envs\\master\\Lib\\site-packages\\ollama\\_client.py:178\u001b[0m, in \u001b[0;36mClient._request\u001b[1;34m(self, cls, stream, *args, **kwargs)\u001b[0m\n\u001b[0;32m    174\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m \u001b[38;5;28mcls\u001b[39m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpart)\n\u001b[0;32m    176\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m inner()\n\u001b[1;32m--> 178\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_request_raw(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\u001b[38;5;241m.\u001b[39mjson())\n",
      "File \u001b[1;32mc:\\Users\\Admin\\miniconda3\\envs\\master\\Lib\\site-packages\\ollama\\_client.py:122\u001b[0m, in \u001b[0;36mClient._request_raw\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    120\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m r\n\u001b[0;32m    121\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m httpx\u001b[38;5;241m.\u001b[39mHTTPStatusError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m--> 122\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m ResponseError(e\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mtext, e\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mstatus_code) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m httpx\u001b[38;5;241m.\u001b[39mConnectError:\n\u001b[0;32m    124\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(CONNECTION_ERROR_MESSAGE) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[1;31mResponseError\u001b[0m: ngrok gateway error\nThe server returned an invalid or incomplete HTTP response.\r\n\r\nERR_NGROK_3004\r\n (status code: 503)"
     ]
    }
   ],
   "source": [
    "system_prompt = \"Tôi có một sơ bộ dữ liệu gồm các lĩnh vực pháp luật Việt Nam bao gồm Bảo Hiểm, Dân sự, Doanh Nghiệp và Giáo dục. \" \\\n",
    "\"Trong đó bao bồm các văn bản hành chính của Chính phủ.\\n\"\n",
    "\n",
    "agent_judgment1 = 'Bạn là một agent dùng để đánh giá câu trả lời. ' \\\n",
    "'Với câu hỏi \"{question}\", Bạn có thể trả lời câu hỏi bằng cơ sở dữ liệu của tôi được hay không (trả lời 1 nếu có thể, trả lời 0 nếu không thế).' \\\n",
    "'Trả lời:' \\\n",
    "\n",
    "agent_search_plan = 'Bạn là một agent để dự đoán thông tin cần truy vấn.\\n' \\\n",
    "'Theo bạn để trả lời câu hỏi \"{question}\", thì cần những thông tin gì và đến từ Lĩnh vực nào?\\n' \\\n",
    "'Trả lời tối đa 3 dòng và theo mẫu <linh_vuc>: <thong_tin_can>, linh_vuc chỉ duy nhất một, 3 câu trả lời cho thể trung Lĩnh vực nhưng khác nhau thông tin cần.\\n' \\\n",
    "'Trả lời: '\n",
    "\n",
    "agent_judgment2 = 'Bạn là một agent reranking' \\\n",
    "\n",
    "\n",
    "\n",
    "question = \"Bảng giá dịch vụ khám chữa bệnh có bảo hiểm\"\n",
    "\n",
    "# PROMPT = agent_search_plan.format(question=question)\n",
    "\n",
    "PROMPT = system_prompt + agent_search_plan.format(question=question)\n",
    "print(PROMPT)\n",
    "\n",
    "response = ollama_client.chat(model='gemma3:12b', messages=[\n",
    "  {\n",
    "    'role': 'user',\n",
    "    'content': PROMPT,\n",
    "    # 'stream': True\n",
    "  },\n",
    "], stream=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*   **Bảo Hiểm:** Thông tin về biểu mẫu, điều khoản, phạm vi chi trả của các gói bảo hiểm y tế, bảng giá dịch vụ được quỹ bảo hiểm thanh toán.\n",
      "*   **Dân sự:** Các quy định về trách nhiệm bồi thường thiệt hại liên quan đến dịch vụ y tế, các thỏa thuận về chi phí khám chữa bệnh có bảo hiểm.\n",
      "*   **Doanh Nghiệp:** Thông tin về các hợp đồng dịch vụ khám bệnh giữa bệnh viện/phòng khám và công ty bảo hiểm, bảng giá dịch vụ đã ký kết.\n"
     ]
    }
   ],
   "source": [
    "print(response.message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tôi có một sơ bộ dữ liệu gồm các lĩnh vực pháp luật Việt Nam bao gồm Bảo Hiểm, Dân sự, Doanh Nghiệp và Giáo dục. Trong đó bao bồm các văn bản hành chính của Chính phủ.\n",
      "Theo bạn để trả lời câu hỏi \"Bảng giá dịch vụ khám chữa bệnh có bảo hiểm\", thì cần những thông tin gì và đến từ Lĩnh vực nào?\n",
      "Trả lời tối đa 3 dòng và theo mẫu <linh_vuc>: <thong_tin_can>, linh_vuc chỉ duy nhất một, 3 câu trả lời cho thể trung Lĩnh vực nhưng khác nhau thông tin cần.\n",
      "Trả lời: \n"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "master",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
